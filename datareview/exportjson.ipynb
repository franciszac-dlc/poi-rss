{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Exportar os json com os dados mais importantes/relevantes\n",
    "- business: business_id; name; city; latitude; longitude; stars; categories\n",
    "- review: review_id; user_id; business_id; stars; date; # texto não será utilizado provavelmente, se for so mudar\n",
    "- user: nada\n",
    "- checkin: nada\n",
    "- tip: user_id; business_id; date # não será utilizado pois não tem stars\n",
    "\n",
    "categories não será transformado em feather pois o formato json é valido.\n",
    "\n",
    "em https://www.yelp.com/dataset/documentation/main a yelp diz que o categories é uma array de string, porém isso é falso, no json que eles dispõem o categories é uma string somente. 2019-08-11 02:16:40\n",
    "\n",
    "Existe business com categorias nulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import algorithms.areamanager as areamanager\n",
    "import numpy as np\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1SWheh84yJXfytovILXOAQ</td>\n",
       "      <td>Arizona Biltmore Golf Club</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>33.522143</td>\n",
       "      <td>-112.018481</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Golf, Active Life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[Specialty Food, Restaurants, Dim Sum, Importe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n",
       "      <td>Musashi Japanese Restaurant</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>35.092564</td>\n",
       "      <td>-80.859132</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Sushi Bars, Restaurants, Japanese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xvX2CttrVhyG2z1dFg_0xw</td>\n",
       "      <td>Farmers Insurance - Paul Lorenz</td>\n",
       "      <td>Goodyear</td>\n",
       "      <td>33.455613</td>\n",
       "      <td>-112.395596</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Insurance, Financial Services]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HhyxOkGAM07SRYtlQ4wMFQ</td>\n",
       "      <td>Queen City Plumbing</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>35.190012</td>\n",
       "      <td>-80.887223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Plumbing, Shopping, Local Services, Home Serv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                             name         city  \\\n",
       "0  1SWheh84yJXfytovILXOAQ       Arizona Biltmore Golf Club      Phoenix   \n",
       "1  QXAEGFB4oINsVuTFxEYKFQ       Emerald Chinese Restaurant  Mississauga   \n",
       "2  gnKjwL_1w79qoiV3IC_xQQ      Musashi Japanese Restaurant    Charlotte   \n",
       "3  xvX2CttrVhyG2z1dFg_0xw  Farmers Insurance - Paul Lorenz     Goodyear   \n",
       "4  HhyxOkGAM07SRYtlQ4wMFQ              Queen City Plumbing    Charlotte   \n",
       "\n",
       "    latitude   longitude  stars  \\\n",
       "0  33.522143 -112.018481    3.0   \n",
       "1  43.605499  -79.652289    2.5   \n",
       "2  35.092564  -80.859132    4.0   \n",
       "3  33.455613 -112.395596    5.0   \n",
       "4  35.190012  -80.887223    4.0   \n",
       "\n",
       "                                          categories  \n",
       "0                                [Golf, Active Life]  \n",
       "1  [Specialty Food, Restaurants, Dim Sum, Importe...  \n",
       "2                [Sushi Bars, Restaurants, Japanese]  \n",
       "3                    [Insurance, Financial Services]  \n",
       "4  [Plumbing, Shopping, Local Services, Home Serv...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbusiness=open(\"../data/business.json\")\n",
    "all_data = list()\n",
    "for i, line in enumerate(fbusiness):  \n",
    "    # json to dict\n",
    "    business_json = json.loads(line)\n",
    "    # add to the data collection\n",
    "    if business_json['categories'] != None:\n",
    "        all_data.append([business_json['business_id'],\n",
    "                         business_json['name'],\n",
    "                         business_json['city'],\n",
    "                         business_json['latitude'],\n",
    "                         business_json['longitude'],\n",
    "                         business_json['stars'],\n",
    "                         business_json['categories'].split(', ')])\n",
    "    else:\n",
    "        all_data.append([business_json['business_id'],\n",
    "                 business_json['name'],\n",
    "                 business_json['city'],\n",
    "                 business_json['latitude'],\n",
    "                 business_json['longitude'],\n",
    "                 business_json['stars'],\n",
    "                 business_json['categories']])\n",
    "# create the DataFrame\n",
    "df = pd.DataFrame(all_data, columns=['business_id', 'name', 'city','latitude', 'longitude', 'stars', 'categories'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/business.csv',index=False)\n",
    "#df.to_pickle('../data/business.pickle')\n",
    "#df.to_feather('../data/business.feather')\n",
    "#df.to_parquet('../data/business.parquet')\n",
    "df=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "freview=open(\"../data/review.json\")\n",
    "all_data = list()\n",
    "df = pd.DataFrame(columns=['review_id', 'user_id', 'business_id', 'date'])\n",
    "df.to_csv('../data/review.csv',index=False)\n",
    "\n",
    "for i, line in enumerate(freview):  \n",
    "    # json to dict\n",
    "    business_json = json.loads(line)\n",
    "    # add to the data collection\n",
    "    all_data.append([business_json['review_id'],\n",
    "                     business_json['user_id'],\n",
    "                     business_json['business_id'],\n",
    "                     business_json['date']])\n",
    "    if i % 1000000==0:\n",
    "        df = pd.DataFrame(all_data, columns=['review_id', 'user_id', 'business_id', 'date'])\n",
    "        df.to_csv('../data/review.csv',header=False,index=False,mode='a')\n",
    "        df=None\n",
    "        all_data = list()\n",
    "# create the DataFrame\n",
    "\n",
    "df = pd.DataFrame(all_data, columns=['review_id', 'user_id', 'business_id', 'date'])\n",
    "df.to_csv('../data/review.csv',header=False,index=False,mode='a')\n",
    "df=None\n",
    "all_data = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#df.to_csv('../data/review.csv')\n",
    "#df.to_pickle('../data/review.pickle')\n",
    "#df.to_feather('../data/review.feather')\n",
    "#df.to_parquet('../data/review.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ftip=open(\"../data/tip.json\")\n",
    "all_data = list()\n",
    "df = pd.DataFrame(columns=['user_id', 'business_id', 'date'])\n",
    "df.to_csv('../data/tip.csv',index=False)\n",
    "\n",
    "\n",
    "for i, line in enumerate(ftip):  \n",
    "    # json to dict\n",
    "    tip_json = json.loads(line)\n",
    "    # add to the data collection\n",
    "    all_data.append([tip_json['user_id'],\n",
    "                     tip_json['business_id'],\n",
    "                     tip_json['date']])\n",
    "    if i % 100000==0:\n",
    "        df = pd.DataFrame(all_data, columns=['user_id', 'business_id','date'])\n",
    "        df.to_csv(\"../data/tip.csv\",header=False,index=False,mode='a')\n",
    "        df=None\n",
    "        all_data = list()\n",
    "# create the DataFrame\n",
    "\n",
    "df = pd.DataFrame(all_data, columns=['user_id', 'business_id', 'date'])\n",
    "df.to_csv(\"../data/tip.csv\",header=False,index=False, mode='a')\n",
    "df=None\n",
    "all_data = list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Export cities dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def export_city(area_case):\n",
    "    df_categories=pd.read_json(\"../data/categories.json\")\n",
    "\n",
    "    # dicionário alias title 2 way\n",
    "    dict_alias_title=dict()\n",
    "    for index, row in df_categories.iterrows():\n",
    "        dict_alias_title[row['alias']]=row['title']\n",
    "        dict_alias_title[row['title']]=row['alias']\n",
    "\n",
    "\n",
    "    category_tree= nx.DiGraph()\n",
    "    for index, row in df_categories.iterrows():\n",
    "        if not row['parents']:\n",
    "            category_tree.add_edge(row['alias'],'root') # root node if no parents\n",
    "        else:\n",
    "            for parent_label in row['parents']:\n",
    "                category_tree.add_edge(row['alias'],parent_label)\n",
    "\n",
    "    undirected_category_tree=category_tree.to_undirected()\n",
    "    # dict alias depth\n",
    "    dict_alias_depth=dict()\n",
    "    for index, row in df_categories.iterrows():\n",
    "        dict_alias_depth[row['alias']]=nx.shortest_path_length(category_tree,row['alias'],'root')\n",
    "    df_categories=None\n",
    "    \n",
    "    city_area=areamanager.delimiter_area(area_case)\n",
    "    def string_to_array(string):\n",
    "        if string == '':\n",
    "            return list()\n",
    "        return eval(string)\n",
    "    def category_filter(categories):\n",
    "        tmp_cat_list=list()\n",
    "        for category in categories:\n",
    "            try:\n",
    "                if dict_alias_depth[dict_alias_title[category]] <= 2:\n",
    "                    tmp_cat_list.append(category)\n",
    "            except:\n",
    "                pass\n",
    "    #             print(\"Error: Category \\\"\"+category+\"\\\" without alias name.\")\n",
    "        return tmp_cat_list\n",
    "\n",
    "    # read business and do some filterings\n",
    "    df_business=pd.read_csv(\"../data/business.csv\",usecols=['business_id','latitude','longitude','categories'],converters={'categories':string_to_array})\n",
    "    df_business=areamanager.pois_in_area(city_area,df_business)\n",
    "    df_business['categories']=df_business.categories.apply(category_filter)\n",
    "    # read review and merge with business\n",
    "    df_review=pd.read_csv(\"../data/review.csv\",usecols=['business_id','user_id','date'])\n",
    "    df_tip=pd.read_csv(\"../data/tip.csv\",usecols=['business_id','user_id','date'])\n",
    "    df_checkin=pd.concat([df_review, df_tip], ignore_index=True)\n",
    "    df_review=None\n",
    "    df_tip=None\n",
    "    df_checkin=pd.merge(df_checkin,df_business,on='business_id')\n",
    "    df_checkin['date']=pd.to_datetime(df_checkin['date'])\n",
    "    df_checkin.head()\n",
    "\n",
    "\n",
    "    df_diff_users_visited=df_checkin[['user_id','business_id']].drop_duplicates().reset_index(drop=True).\\\n",
    "    groupby('business_id').count().reset_index().rename(columns={\"user_id\":\"diffusersvisited\"})\n",
    "\n",
    "    df_diff_users_visited=df_diff_users_visited[df_diff_users_visited['diffusersvisited']>=5]\n",
    "    del df_diff_users_visited['diffusersvisited']\n",
    "    df_checkin=pd.merge(df_checkin,df_diff_users_visited,on='business_id',how='inner')\n",
    "    df_checkin.count()\n",
    "\n",
    "\n",
    "    df_checkin['Count']=df_checkin.groupby(['user_id'])['user_id'].transform('count')\n",
    "    df_checkin=df_checkin[df_checkin['Count']>=20]\n",
    "    del df_checkin['Count']\n",
    "    df_checkin.count()\n",
    "\n",
    "    areamanager.poi_set_subarea(city_area,df_checkin,0.5)\n",
    "\n",
    "    return df_checkin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area selected: Las Vegas\n"
     ]
    }
   ],
   "source": [
    "export_city(\"lasvegas\").to_csv(\"../data/checkin/lasvegas.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area selected: Phoenix\n"
     ]
    }
   ],
   "source": [
    "export_city(\"phoenix\").to_csv(\"../data/checkin/phoenix.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area selected: Charlotte\n"
     ]
    }
   ],
   "source": [
    "export_city(\"charlotte\").to_csv(\"../data/checkin/charlotte.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area selected: Madison\n"
     ]
    }
   ],
   "source": [
    "export_city(\"madison\").to_csv(\"../data/checkin/madison.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def city_pois(area_case):\n",
    "    df_categories=pd.read_json(\"../data/categories.json\")\n",
    "\n",
    "    # dicionário alias title 2 way\n",
    "    dict_alias_title=dict()\n",
    "    for index, row in df_categories.iterrows():\n",
    "        dict_alias_title[row['alias']]=row['title']\n",
    "        dict_alias_title[row['title']]=row['alias']\n",
    "\n",
    "\n",
    "    category_tree= nx.DiGraph()\n",
    "    for index, row in df_categories.iterrows():\n",
    "        if not row['parents']:\n",
    "            category_tree.add_edge(row['alias'],'root') # root node if no parents\n",
    "        else:\n",
    "            for parent_label in row['parents']:\n",
    "                category_tree.add_edge(row['alias'],parent_label)\n",
    "\n",
    "    undirected_category_tree=category_tree.to_undirected()\n",
    "    # dict alias depth\n",
    "    dict_alias_depth=dict()\n",
    "    for index, row in df_categories.iterrows():\n",
    "        dict_alias_depth[row['alias']]=nx.shortest_path_length(category_tree,row['alias'],'root')\n",
    "    df_categories=None\n",
    "    \n",
    "    city_area=areamanager.delimiter_area(area_case)\n",
    "    def string_to_array(string):\n",
    "        if string == '':\n",
    "            return list()\n",
    "        return eval(string)\n",
    "    def category_filter(categories):\n",
    "        tmp_cat_list=list()\n",
    "        for category in categories:\n",
    "            try:\n",
    "                if dict_alias_depth[dict_alias_title[category]] <= 2:\n",
    "                    tmp_cat_list.append(category)\n",
    "            except:\n",
    "                pass\n",
    "    #             print(\"Error: Category \\\"\"+category+\"\\\" without alias name.\")\n",
    "        return tmp_cat_list\n",
    "\n",
    "    # read business and do some filterings\n",
    "    df_business=pd.read_csv(\"../data/business.csv\",usecols=['business_id','latitude','longitude','categories'],converters={'categories':string_to_array})\n",
    "    df_business=areamanager.pois_in_area(city_area,df_business)\n",
    "    df_business['categories']=df_business.categories.apply(category_filter)\n",
    "    areamanager.poi_set_subarea(city_area,df_business,0.5)\n",
    "    return df_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area selected: Las Vegas\n"
     ]
    }
   ],
   "source": [
    "city_pois(\"lasvegas\").to_csv(\"../data/poi/lasvegas.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area selected: Phoenix\n"
     ]
    }
   ],
   "source": [
    "city_pois(\"phoenix\").to_csv(\"../data/poi/phoenix.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area selected: Charlotte\n"
     ]
    }
   ],
   "source": [
    "city_pois(\"charlotte\").to_csv(\"../data/poi/charlotte.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area selected: Madison\n"
     ]
    }
   ],
   "source": [
    "city_pois(\"madison\").to_csv(\"../data/poi/madison.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users json to csv with only user_id and friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuser=open(\"../data/user.json\")\n",
    "all_data = list()\n",
    "df = pd.DataFrame(columns=['user_id', 'friends'])\n",
    "df.to_csv('../data/user.csv',index=False)\n",
    "\n",
    "for i, line in enumerate(fuser):  \n",
    "    # json to dict\n",
    "    obj_json = json.loads(line)\n",
    "    # add to the data collection\n",
    "    all_data.append([obj_json['user_id'],\n",
    "                     obj_json['friends'].split(', ')])\n",
    "    \n",
    "    if i % 100000==0:\n",
    "        df = pd.DataFrame(all_data, columns=['user_id', 'friends'])\n",
    "        df.to_csv('../data/user.csv',header=False,index=False,mode='a')\n",
    "        df=None\n",
    "        all_data = list()\n",
    "# create the DataFrame\n",
    "\n",
    "df = pd.DataFrame(all_data, columns=['user_id', 'friends'])\n",
    "df.to_csv('../data/user.csv',header=False,index=False,mode='a')\n",
    "df=None\n",
    "all_data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_array(string):\n",
    "    if string == '':\n",
    "        return list()\n",
    "    return eval(string)\n",
    "df_user=pd.read_csv(\"../data/user.csv\",converters={'friends':string_to_array})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export cities users with their friends that are in the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def friend_filter_city(friends,df_city_users):\n",
    "    return pd.merge(pd.DataFrame(friends,columns=['user_id']),df_city_users,on='user_id').loc[:,'user_id'].tolist()\n",
    "cities_name=['lasvegas','phoenix','charlotte','madison']\n",
    "for city_name in cities_name:\n",
    "    df_city_users=pd.read_csv(\"../data/checkin/\"+city_name+\".csv\",usecols=['user_id']).drop_duplicates().reset_index(drop=True)\n",
    "    df_city_user=pd.merge(df_user,df_city_users,on='user_id')\n",
    "    df_city_user['friends']=df_city_user.friends.apply(lambda friends: friend_filter_city(friends,df_city_users))\n",
    "    df_city_user.to_csv(\"../data/user/\"+city_name+\".csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "exportjson.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
