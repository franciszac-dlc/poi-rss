{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoCat experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lib.recommenders as rec\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.areamanager\n",
    "import math\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "import lib.geocat.objfunc as gcobjfunc\n",
    "import lib.cat_utils as cat_utils\n",
    "\n",
    "from lib.constants import experiment_constants\n",
    "import lib.metrics as metrics\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.metricscontroller import MetricsController\n",
    "\n",
    "import lib.pgc.pgc as pgc\n",
    "\n",
    "def string_to_array(string):\n",
    "    if string == '':\n",
    "        return list()\n",
    "    return eval(string)\n",
    "importlib.reload(lib.metricscontroller)\n",
    "importlib.reload(lib.constants)\n",
    "importlib.reload(rec)\n",
    "importlib.reload(gcobjfunc)\n",
    "importlib.reload(cat_utils)\n",
    "importlib.reload(lib.metricscontroller)\n",
    "N=experiment_constants.N\n",
    "K=experiment_constants.K\n",
    "CITY=experiment_constants.CITY\n",
    "METRICS_K=experiment_constants.METRICS_K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train load\n",
    "data_checkin_train = pickle.load(open(\"../data/checkin/train/\"+CITY+\".pickle\",\"rb\"))\n",
    "\n",
    "#Test load\n",
    "ground_truth = defaultdict(set)\n",
    "for checkin in pickle.load(open(\"../data/checkin/test/\"+CITY+\".pickle\",\"rb\")):\n",
    "    ground_truth[checkin['user_id']].add(checkin['poi_id'])\n",
    "#Pois load\n",
    "poi_coos = {}\n",
    "poi_cats = {}\n",
    "for poi_id,poi in pickle.load(open(\"../data/poi/\"+CITY+\".pickle\",\"rb\")).items():\n",
    "    poi_coos[poi_id] = tuple([poi['latitude'],poi['longitude']])\n",
    "    poi_cats[poi_id] = poi['categories']\n",
    "    \n",
    "#Social relations load\n",
    "social_relations = defaultdict(list)\n",
    "for user_id,friends in pickle.load(open(\"../data/user/\"+CITY+\".pickle\",\"rb\")).items():\n",
    "    social_relations[user_id]=friends\n",
    "\n",
    "user_num = len(social_relations)\n",
    "poi_num = len(poi_coos)\n",
    "user_num,poi_num\n",
    "\n",
    "# Cat Hierarchy load\n",
    "dict_alias_title,category_tree,dict_alias_depth=cat_utils.cat_structs(\"../data/categories.json\")\n",
    "undirected_category_tree=category_tree.to_undirected()\n",
    "\n",
    "# Training matrix create\n",
    "training_matrix = np.zeros((user_num, poi_num))\n",
    "for checkin in data_checkin_train:\n",
    "    training_matrix[checkin['user_id'],checkin['poi_id']]+=1\n",
    "\n",
    "# poi neighbors load\n",
    "poi_neighbors=pickle.load(open(\"../data/neighbor/\"+CITY+\".pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_checkin=pd.read_csv(\"../data/checkin/\"+CITY+\".csv\",converters={'categories':string_to_array})\n",
    "\n",
    "# df_checkin_train=pd.read_csv(\"../data/checkin/train/\"+CITY+\".csv\",converters={'categories':string_to_array})\n",
    "\n",
    "\n",
    "# users_id=df_checkin['user_id'].drop_duplicates().reset_index(drop=True)\n",
    "# pois_id=df_checkin['business_id'].drop_duplicates().reset_index(drop=True)\n",
    "# user_num=len(users_id)\n",
    "# poi_num=len(pois_id)\n",
    "\n",
    "\n",
    "# df_checkin_train=df_checkin_train.set_index('user_id')\n",
    "\n",
    "# df_checkin_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_checkin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_checkin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_checkin_test=pd.read_csv(\"../data/checkin/test/\"+CITY+\".csv\",converters={'categories':string_to_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth = defaultdict(set)\n",
    "# for index,row in df_checkin_test[['user_id','business_id']].drop_duplicates().iterrows():\n",
    "#     ground_truth[row['user_id']].add(row['business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poi_coos = {}\n",
    "# for lid,latlon in df_checkin[['business_id','latitude','longitude']].reset_index(drop=True).drop_duplicates().set_index('business_id').iterrows():\n",
    "#     poi_coos[lid] = tuple(latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgc.cmean_dist_pois(poi_coos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poi_cats = {}\n",
    "# for lid,row in df_checkin[['business_id','categories']].reset_index(drop=True).drop_duplicates(subset=['business_id']).set_index('business_id').iterrows():\n",
    "#     poi_cats[lid] = row.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_alias_title,category_tree,dict_alias_depth=cat_utils.cat_structs()\n",
    "# undirected_category_tree=category_tree.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_matrix = np.zeros((user_num, poi_num))\n",
    "# for user_id,poi_id in df_checkin_train.business_id.iteritems():\n",
    "#    # print(user_id,poi_id)\n",
    "#     training_matrix[user_id,poi_id]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uids = list(range(user_num))\n",
    "all_lids = list(range(poi_num))\n",
    "\n",
    "#np.random.shuffle(all_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predict={}\n",
    "for index,row in pd.read_csv(\"../data/result/reclist/sigir11_top_100.txt\",header=None).iterrows():\n",
    "    user_id=row[0]\n",
    "    lid_list=row[1]\n",
    "    user_predict[user_id]=eval(lid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_poi_neighbor=pd.read_csv(\"../data/neighbor/\"+CITY+\".csv\",converters={'neighbors':string_to_array})\n",
    "# df_poi_neighbor=df_poi_neighbor.set_index(\"business_id\")\n",
    "# poi_neighbors={}\n",
    "# for lid,row in df_poi_neighbor.iterrows():\n",
    "#     neighbors=row['neighbors']\n",
    "#     poi_neighbors[lid]=neighbors\n",
    "# df_poi_neighbor=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print(MetricsController(metrics=['precision','recall','pr','ild','gc'],algorithm='usg',k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in mcs:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rec)\n",
    "importlib.reload(gcobjfunc)\n",
    "#precision,recall,ild,gc,pr = [],[],[],[],[]\n",
    "\n",
    "range_K=range(K)\n",
    "overall_scores=np.zeros(poi_num)\n",
    "mcs=list()\n",
    "for k in METRICS_K:\n",
    "    mcs.append(MetricsController(metrics=['precision','recall','pr','ild','gc','epc'],algorithm='mostpopular_geocat',k=k))\n",
    "pop=epc_pop_list(training_matrix)\n",
    "epc_numerator=list()\n",
    "epc_denominator=list()\n",
    "\n",
    "for cnt, uid in enumerate(all_uids):\n",
    "    if uid in ground_truth:\n",
    "        \n",
    "        pois_score=rec.mostpopularnp(training_matrix,uid)\n",
    "        tmp_rec_list=list(reversed(np.argsort(pois_score)))[0:N]\n",
    "        tmp_score_list=list(reversed(np.sort(pois_score)))[0:N]\n",
    "        \n",
    "        actual=ground_truth[uid]\n",
    "        predicted=tmp_rec_list\n",
    "        \n",
    "        #print(list(reversed(np.sort(pois_score)))[0:N])\n",
    "        \n",
    "        #print(tmp_rec_list)\n",
    "        #break\n",
    "        #tmp_rec_list=user_predict[uid][:N]\n",
    "        rec_list=[]\n",
    "        \n",
    "        lids=training_matrix[uid].nonzero()[0]\n",
    "        \n",
    "        lid_visits=training_matrix[:,lids].sum(axis=0)\n",
    "        mean_visits=lid_visits.mean()\n",
    "        relevant_lids=lids[lid_visits>mean_visits]\n",
    "        relevant_cats=set()\n",
    "        for lid in relevant_lids:\n",
    "            relevant_cats.update(poi_cats[lid])\n",
    "        # log_size=training_matrix[0,training_matrix[0,:].nonzero()[0]].sum()\n",
    "        user_log=training_matrix[uid]\n",
    "        #print(mean_visits)\n",
    "        log_poi_ids=list()\n",
    "        poi_cover=list()\n",
    "        for lid in user_log.nonzero()[0]:\n",
    "            for visits in range(int(user_log[lid])):\n",
    "                poi_cover.append(0)\n",
    "                log_poi_ids.append(lid)\n",
    "        log_size=len(log_poi_ids)\n",
    "        assert user_log[user_log.nonzero()[0]].sum() == len(poi_cover)\n",
    "#         print(uid)\n",
    "#         print(\"Count:\",cnt)\n",
    "        div_geo_cat_weight = 0.75 # beta,this is here because of the work to be done on parameter customization for each user\n",
    "        div_weight = 0.5 # lambda, geo vs cat\n",
    "        current_proportionality=0\n",
    "        final_scores=[]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        log_neighbors=dict()\n",
    "        for poi_id in tmp_rec_list:\n",
    "            neighbors=list()\n",
    "            for id_neighbor in poi_neighbors[poi_id]:\n",
    "                for i in range(log_size):\n",
    "                    log_poi_id=log_poi_ids[i]\n",
    "                    if log_poi_id == id_neighbor:\n",
    "                        neighbors.append(i)\n",
    "            log_neighbors[poi_id]=neighbors\n",
    "\n",
    "        \n",
    "        for i in range_K:\n",
    "            #print(i)\n",
    "            poi_to_insert=None\n",
    "            max_objective_value=-200\n",
    "            for j in range(len(tmp_rec_list)):\n",
    "                candidate_poi_id=tmp_rec_list[j]\n",
    "                candidate_score=tmp_score_list[j]\n",
    "                ild_div=gcobjfunc.min_dist_to_list_cat(candidate_poi_id,rec_list,poi_cats,undirected_category_tree)\n",
    "                gc_div=gcobjfunc.gc(candidate_poi_id,rec_list,relevant_cats,poi_cats)\n",
    "                pr=gcobjfunc.update_geo_cov(candidate_poi_id,log_poi_ids,K,poi_cover.copy(),poi_neighbors,log_neighbors[candidate_poi_id])\n",
    "                \n",
    "                objective_value=gcobjfunc.ILD_GC_PR(candidate_score,ild_div,gc_div,pr,current_proportionality,K,div_geo_cat_weight,div_weight)\n",
    "                #print(candidate_poi_id,ild_div,gc_div,max(0,pr-current_proportionality),objective_value)\n",
    "                #print(candidate_poi_id,objective_value)\n",
    "\n",
    "                if objective_value > max_objective_value:\n",
    "                    max_objective_value=objective_value\n",
    "                    poi_to_insert=candidate_poi_id\n",
    "                pass\n",
    "            if poi_to_insert is not None:\n",
    "                #print(poi_to_insert,max_objective_value)\n",
    "                \n",
    "                rm_idx=tmp_rec_list.index(poi_to_insert)\n",
    "                \n",
    "                tmp_rec_list.pop(rm_idx)\n",
    "                tmp_score_list.pop(rm_idx)\n",
    "                rec_list.append(poi_to_insert)\n",
    "                final_scores.append(max_objective_value)\n",
    "                # remove from tmp_rec_list\n",
    "                current_proportionality=gcobjfunc.update_geo_cov(poi_to_insert,log_poi_ids,K,poi_cover,poi_neighbors,log_neighbors[poi_to_insert])\n",
    "                #print(current_proportionality)\n",
    "        print(\"time → %fs\" % (time.time()-start_time))\n",
    "#         predicted=np.array(rec_list)[list(reversed(np.argsort(final_scores)))]\n",
    "        \n",
    "        for i,k in enumerate(METRICS_K):\n",
    "            predicted_at_k=predicted[:k]\n",
    "            \n",
    "            precision_val=metrics.precisionk(actual, predicted_at_k)\n",
    "            rec_val=metrics.recallk(actual, predicted_at_k)\n",
    "            pr_val=metrics.prk(training_matrix[uid],predicted_at_k,poi_neighbors)\n",
    "            ild_val=metrics.ildk(predicted_at_k,poi_cats,undirected_category_tree)\n",
    "            gc_val=metrics.gck(uid,training_matrix,poi_cats,predicted_at_k)\n",
    "            \n",
    "            epc_val=metrics.epck(predicted_at_k,actual,uid,pop,epc_numerator,epc_denominator)\n",
    "            \n",
    "            mcs[i].append_data([precision_val,rec_val,pr_val,ild_val,gc_val,epc_val])\n",
    "            print(\"userid →\",uid,end=',')\n",
    "            mcs[i].print_metrics()\n",
    "            \n",
    "            \n",
    "            \n",
    "#,f\"prec@{N}: {np.mean(precision)}, rec@{N}: {np.mean(recall)}\")\n",
    "#         print(final_scores)\n",
    "#         print(rec_list)\n",
    "#         print(list(reversed(np.sort(final_scores))))\n",
    "#         print(np.array(rec_list)[list(reversed(np.argsort(final_scores)))])\n",
    "#         print()\n",
    "for i in mcs:\n",
    "    i.fwrite_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
