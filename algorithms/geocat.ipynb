{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoCat experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lib.recommenders as rec\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.areamanager\n",
    "import math\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "import lib.geocat.objfunc as gcobjfunc\n",
    "import lib.geocat.cat_utils as cat_utils\n",
    "from lib.constants import experiment_constants\n",
    "import lib.metrics as metrics\n",
    "%matplotlib inline\n",
    "def string_to_array(string):\n",
    "    if string == '':\n",
    "        return list()\n",
    "    return eval(string)\n",
    "\n",
    "\n",
    "importlib.reload(rec)\n",
    "importlib.reload(gcobjfunc)\n",
    "importlib.reload(cat_utils)\n",
    "CITY=experiment_constants.get_city()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>categories</th>\n",
       "      <th>subarea_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1744</td>\n",
       "      <td>2017-12-15 14:05:01</td>\n",
       "      <td>43.075012</td>\n",
       "      <td>-89.447498</td>\n",
       "      <td>[desserts, cafes, coffee]</td>\n",
       "      <td>2143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2746</td>\n",
       "      <td>2018-01-18 20:57:23</td>\n",
       "      <td>43.106774</td>\n",
       "      <td>-89.497738</td>\n",
       "      <td>[desserts, tradamerican, diners, gastropubs, b...</td>\n",
       "      <td>2641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>2018-01-23 23:14:37</td>\n",
       "      <td>43.072654</td>\n",
       "      <td>-89.384062</td>\n",
       "      <td>[bars, mexican]</td>\n",
       "      <td>2133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>2018-01-27 02:17:06</td>\n",
       "      <td>43.072439</td>\n",
       "      <td>-89.384610</td>\n",
       "      <td>[tradamerican, bars]</td>\n",
       "      <td>2133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-01-27 02:31:26</td>\n",
       "      <td>43.075100</td>\n",
       "      <td>-89.381069</td>\n",
       "      <td>[mexican]</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         business_id                 date   latitude  longitude  \\\n",
       "user_id                                                           \n",
       "0               1744  2017-12-15 14:05:01  43.075012 -89.447498   \n",
       "0               2746  2018-01-18 20:57:23  43.106774 -89.497738   \n",
       "0                 30  2018-01-23 23:14:37  43.072654 -89.384062   \n",
       "0                432  2018-01-27 02:17:06  43.072439 -89.384610   \n",
       "0                 22  2018-01-27 02:31:26  43.075100 -89.381069   \n",
       "\n",
       "                                                categories  subarea_id  \n",
       "user_id                                                                 \n",
       "0                                [desserts, cafes, coffee]      2143.0  \n",
       "0        [desserts, tradamerican, diners, gastropubs, b...      2641.0  \n",
       "0                                          [bars, mexican]      2133.0  \n",
       "0                                     [tradamerican, bars]      2133.0  \n",
       "0                                                [mexican]      2132.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkin=pd.read_csv(\"../data/checkin/\"+CITY+\".csv\",converters={'categories':string_to_array})\n",
    "\n",
    "df_checkin_train=pd.read_csv(\"../data/checkin/train/\"+CITY+\".csv\",converters={'categories':string_to_array})\n",
    "\n",
    "\n",
    "users_id=df_checkin['user_id'].drop_duplicates().reset_index(drop=True)\n",
    "pois_id=df_checkin['business_id'].drop_duplicates().reset_index(drop=True)\n",
    "user_num=len(users_id)\n",
    "poi_num=len(pois_id)\n",
    "\n",
    "\n",
    "df_checkin_train=df_checkin_train.set_index('user_id')\n",
    "\n",
    "df_checkin_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkin_test=pd.read_csv(\"../data/checkin/test/\"+CITY+\".csv\",converters={'categories':string_to_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = defaultdict(set)\n",
    "for index,row in df_checkin_test[['user_id','business_id']].drop_duplicates().iterrows():\n",
    "    ground_truth[row['user_id']].add(row['business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_coos = {}\n",
    "for lid,latlon in df_checkin[['business_id','latitude','longitude']].reset_index(drop=True).drop_duplicates().set_index('business_id').iterrows():\n",
    "    poi_coos[lid] = tuple(latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.406857808147945"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lib.geo_utils as geo_utils\n",
    "a=np.array([])\n",
    "b=np.array([])\n",
    "for i,j in poi_coos.items():\n",
    "    a=np.append(a,j[0])\n",
    "    b=np.append(a,j[1])\n",
    "lat,lon = a.mean(),b.mean()\n",
    "md=0\n",
    "for i in range(len(a)):\n",
    "    md+=geo_utils.haversine(lat,lon,a[i],b[i])\n",
    "md/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_cats = {}\n",
    "for lid,row in df_checkin[['business_id','categories']].reset_index(drop=True).drop_duplicates(subset=['business_id']).set_index('business_id').iterrows():\n",
    "    poi_cats[lid] = row.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_alias_title,category_tree,dict_alias_depth=cat_utils.cat_structs()\n",
    "undirected_category_tree=category_tree.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_matrix = np.zeros((user_num, poi_num))\n",
    "for user_id,poi_id in df_checkin_train.business_id.iteritems():\n",
    "   # print(user_id,poi_id)\n",
    "    training_matrix[user_id,poi_id]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uids = list(range(user_num))\n",
    "all_lids = list(range(poi_num))\n",
    "\n",
    "#np.random.shuffle(all_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predict={}\n",
    "for index,row in pd.read_csv(\"../data/result/sigir11_top_100.txt\",header=None).iterrows():\n",
    "    user_id=row[0]\n",
    "    lid_list=row[1]\n",
    "    user_predict[user_id]=eval(lid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poi_neighbor=pd.read_csv(\"../data/neighbor/\"+CITY+\".csv\",converters={'neighbors':string_to_array})\n",
    "df_poi_neighbor=df_poi_neighbor.set_index(\"business_id\")\n",
    "poi_neighbors={}\n",
    "for lid,row in df_poi_neighbor.iterrows():\n",
    "    neighbors=row['neighbors']\n",
    "    poi_neighbors[lid]=neighbors\n",
    "df_poi_neighbor=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rec)\n",
    "importlib.reload(gcobjfunc)\n",
    "precision,recall,ild,gc,pr = [],[],[],[],[]\n",
    "N=80\n",
    "K=20\n",
    "range_K=range(K)\n",
    "overall_scores=np.zeros(poi_num)\n",
    "\n",
    "for cnt, uid in enumerate(all_uids):\n",
    "    if uid in ground_truth:\n",
    "        \n",
    "        pois_score=rec.mostpopularnp(training_matrix,uid)\n",
    "        tmp_rec_list=list(reversed(np.argsort(pois_score)))[0:N]\n",
    "        tmp_score_list=list(reversed(np.sort(pois_score)))[0:N]\n",
    "        \n",
    "        actual=ground_truth[uid]\n",
    "        predicted=tmp_rec_list\n",
    "        precision.append(metrics.precisionk(actual, predicted))\n",
    "        recall.append(metrics.recallk(actual, predicted))\n",
    "        pr.append(metrics.prk(training_matrix[uid],predicted,poi_neighbors))\n",
    "        ild.append(metrics.ildk(predicted,poi_cats,undirected_category_tree))\n",
    "        gc.append(metrics.gck(uid,training_matrix,poi_cats,predicted))\n",
    "        print(\"userid →\",uid,f\"prec@{N}: {np.mean(precision)}, rec@{N}: {np.mean(recall)}\")\n",
    "        continue\n",
    "        #print(list(reversed(np.sort(pois_score)))[0:N])\n",
    "        \n",
    "        #print(tmp_rec_list)\n",
    "        #break\n",
    "        #tmp_rec_list=user_predict[uid][:N]\n",
    "        rec_list=[]\n",
    "        \n",
    "        lids=training_matrix[uid].nonzero()[0]\n",
    "        \n",
    "        lid_visits=training_matrix[:,lids].sum(axis=0)\n",
    "        mean_visits=lid_visits.mean()\n",
    "        relevant_lids=lids[lid_visits>mean_visits]\n",
    "        relevant_cats=set()\n",
    "        for lid in relevant_lids:\n",
    "            relevant_cats.update(poi_cats[lid])\n",
    "        # log_size=training_matrix[0,training_matrix[0,:].nonzero()[0]].sum()\n",
    "        user_log=training_matrix[uid]\n",
    "        #print(mean_visits)\n",
    "        log_poi_ids=list()\n",
    "        poi_cover=list()\n",
    "        for lid in user_log.nonzero()[0]:\n",
    "            for visits in range(int(user_log[lid])):\n",
    "                poi_cover.append(0)\n",
    "                log_poi_ids.append(lid)\n",
    "        log_size=len(log_poi_ids)\n",
    "        assert user_log[user_log.nonzero()[0]].sum() == len(poi_cover)\n",
    "#         print(uid)\n",
    "#         print(\"Count:\",cnt)\n",
    "        div_geo_cat_weight = 0.75 # beta,this is here because of the work to be done on parameter customization for each user\n",
    "        div_weight = 0.5 # lambda, geo vs cat\n",
    "        current_proportionality=0\n",
    "        final_scores=[]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        log_neighbors=dict()\n",
    "        for poi_id in tmp_rec_list:\n",
    "            neighbors=list()\n",
    "            for id_neighbor in poi_neighbors[poi_id]:\n",
    "                for i in range(log_size):\n",
    "                    log_poi_id=log_poi_ids[i]\n",
    "                    if log_poi_id == id_neighbor:\n",
    "                        neighbors.append(i)\n",
    "            log_neighbors[poi_id]=neighbors\n",
    "\n",
    "        \n",
    "        for i in range_K:\n",
    "            #print(i)\n",
    "            poi_to_insert=None\n",
    "            max_objective_value=-200\n",
    "            for j in range(len(tmp_rec_list)):\n",
    "                candidate_poi_id=tmp_rec_list[j]\n",
    "                candidate_score=tmp_score_list[j]\n",
    "                ild_div=gcobjfunc.min_dist_to_list_cat(candidate_poi_id,rec_list,poi_cats,undirected_category_tree)\n",
    "                gc_div=gcobjfunc.gc(candidate_poi_id,rec_list,relevant_cats,poi_cats)\n",
    "                pr=gcobjfunc.update_geo_cov(candidate_poi_id,log_poi_ids,K,poi_cover.copy(),poi_neighbors,log_neighbors[candidate_poi_id])\n",
    "                \n",
    "                objective_value=gcobjfunc.ILD_GC_PR(candidate_score,ild_div,gc_div,pr,current_proportionality,K,div_geo_cat_weight,div_weight)\n",
    "                #print(candidate_poi_id,ild_div,gc_div,max(0,pr-current_proportionality),objective_value)\n",
    "                #print(candidate_poi_id,objective_value)\n",
    "\n",
    "                if objective_value > max_objective_value:\n",
    "                    max_objective_value=objective_value\n",
    "                    poi_to_insert=candidate_poi_id\n",
    "                pass\n",
    "            if poi_to_insert is not None:\n",
    "                #print(poi_to_insert,max_objective_value)\n",
    "                \n",
    "                rm_idx=tmp_rec_list.index(poi_to_insert)\n",
    "                \n",
    "                tmp_rec_list.pop(rm_idx)\n",
    "                tmp_score_list.pop(rm_idx)\n",
    "                rec_list.append(poi_to_insert)\n",
    "                final_scores.append(max_objective_value)\n",
    "                # remove from tmp_rec_list\n",
    "                current_proportionality=gcobjfunc.update_geo_cov(poi_to_insert,log_poi_ids,K,poi_cover,poi_neighbors,log_neighbors[poi_to_insert])\n",
    "                #print(current_proportionality)\n",
    "        print(\"time → %fs\" % (time.time()-start_time))\n",
    "#         print(final_scores)\n",
    "#         print(rec_list)\n",
    "        #print(list(reversed(np.sort(final_scores))))\n",
    "        #print(np.array(rec_list)[list(reversed(np.argsort(final_scores)))])\n",
    "        #print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
