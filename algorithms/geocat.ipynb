{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoCat experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import importlib\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lib.recommenders as rec\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.constants import experiment_constants\n",
    "import lib.metrics as metrics\n",
    "from lib.metricscontroller import MetricsController\n",
    "import lib.geocat.objfunc as gcobjfunc\n",
    "import lib.cat_utils as cat_utils\n",
    "import lib.pgc.pgc as pgc\n",
    "import lib.areamanager\n",
    "\n",
    "def string_to_array(string):\n",
    "    if string == '':\n",
    "        return list()\n",
    "    return eval(string)\n",
    "\n",
    "importlib.reload(lib.metricscontroller)\n",
    "importlib.reload(lib.constants)\n",
    "importlib.reload(rec)\n",
    "importlib.reload(gcobjfunc)\n",
    "importlib.reload(cat_utils)\n",
    "importlib.reload(lib.metricscontroller)\n",
    "\n",
    "N=experiment_constants.N\n",
    "K=experiment_constants.K\n",
    "CITY=experiment_constants.CITY\n",
    "METRICS_K=experiment_constants.METRICS_K\n",
    "print(CITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train load\n",
    "data_checkin_train = pickle.load(open(\"../data/checkin/train/\"+CITY+\".pickle\",\"rb\"))\n",
    "\n",
    "#Test load\n",
    "ground_truth = defaultdict(set)\n",
    "for checkin in pickle.load(open(\"../data/checkin/test/\"+CITY+\".pickle\",\"rb\")):\n",
    "    ground_truth[checkin['user_id']].add(checkin['poi_id'])\n",
    "#Pois load\n",
    "poi_coos = {}\n",
    "poi_cats = {}\n",
    "for poi_id,poi in pickle.load(open(\"../data/poi/\"+CITY+\".pickle\",\"rb\")).items():\n",
    "    poi_coos[poi_id] = tuple([poi['latitude'],poi['longitude']])\n",
    "    poi_cats[poi_id] = poi['categories']\n",
    "    \n",
    "#Social relations load\n",
    "social_relations = defaultdict(list)\n",
    "for user_id,friends in pickle.load(open(\"../data/user/\"+CITY+\".pickle\",\"rb\")).items():\n",
    "    social_relations[user_id]=friends\n",
    "\n",
    "user_num = len(social_relations)\n",
    "poi_num = len(poi_coos)\n",
    "user_num,poi_num\n",
    "\n",
    "# Cat Hierarchy load\n",
    "dict_alias_title,category_tree,dict_alias_depth=cat_utils.cat_structs(\"../data/categories.json\")\n",
    "undirected_category_tree=category_tree.to_undirected()\n",
    "\n",
    "# Training matrix create\n",
    "training_matrix = np.zeros((user_num, poi_num))\n",
    "for checkin in data_checkin_train:\n",
    "    training_matrix[checkin['user_id'],checkin['poi_id']]+=1\n",
    "\n",
    "# poi neighbors load\n",
    "poi_neighbors=pickle.load(open(\"../data/neighbor/\"+CITY+\".pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgc.cmean_dist_pois(poi_coos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uids = list(range(user_num))\n",
    "all_lids = list(range(poi_num))\n",
    "\n",
    "#np.random.shuffle(all_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr=open(\"../data/result/reclist/\"+CITY+\"_sigir11_top_100.json\")\n",
    "user_predicted={}\n",
    "user_overall_scores={}\n",
    "\n",
    "for line in fr:\n",
    "    obj=json.loads(line)\n",
    "    user_predicted[obj['user_id']]=obj['predicted']\n",
    "    user_overall_scores[obj['user_id']]=obj['scores']\n",
    "\n",
    "len(user_predicted),len(user_overall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"../data/result/reclist/sigir11_top_100.txt\",header=None,sep='\\t')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_predict={}\n",
    "# for index,row in pd.read_csv(\"../data/result/reclist/sigir11_top_100.txt\",header=None).iterrows():\n",
    "#     user_id=row[0]\n",
    "#     lid_list=row[1]\n",
    "#     user_predict[user_id]=eval(lid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rec)\n",
    "importlib.reload(gcobjfunc)\n",
    "importlib.reload(metrics)\n",
    "#precision,recall,ild,gc,pr = [],[],[],[],[]\n",
    "\n",
    "range_K=range(K)\n",
    "\n",
    "# mcs=list()\n",
    "# for k in METRICS_K:\n",
    "#     mcs.append(MetricsController(metrics=['precision','recall','pr','ild','gc','epc'],algorithm='mostpopular_geocat',k=k))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_scores=np.zeros(poi_num)\n",
    "\n",
    "# for cnt, uid in enumerate(all_uids):\n",
    "def run_geocat(uid):\n",
    "    if uid in ground_truth:\n",
    "        \n",
    "        pois_score=rec.mostpopularnp(training_matrix,uid)\n",
    "        predicted=list(reversed(np.argsort(pois_score)))[0:N]\n",
    "        overall_scores=list(reversed(np.sort(pois_score)))[0:N]\n",
    "        \n",
    "        actual=ground_truth[uid]\n",
    "        start_time = time.time()\n",
    " \n",
    "        predicted,overall_scores=gcobjfunc.geocat(uid,training_matrix,predicted,overall_scores,actual,\n",
    "                         poi_cats,poi_neighbors,K,undirected_category_tree)\n",
    "\n",
    "        print(\"uid → %d, time → %fs\" % (uid,time.time()-start_time))\n",
    "        \n",
    "        predicted=np.array(predicted)[list(reversed(np.argsort(overall_scores)))]\n",
    "        overall_scores=list(reversed(np.sort(overall_scores)))\n",
    "\n",
    "        \n",
    "        return json.dumps({'user_id':uid,'predicted':list(map(int,predicted)),'scores':list(map(float,overall_scores))})+\"\\n\"                                                      \n",
    "    return None\n",
    "        \n",
    "        \n",
    "#         for i,k in enumerate(METRICS_K):\n",
    "#             predicted_at_k=predicted[:k]\n",
    "            \n",
    "#             precision_val=metrics.precisionk(actual, predicted_at_k)\n",
    "#             rec_val=metrics.recallk(actual, predicted_at_k)\n",
    "#             pr_val=metrics.prk(training_matrix[uid],predicted_at_k,poi_neighbors)\n",
    "#             ild_val=metrics.ildk(predicted_at_k,poi_cats,undirected_category_tree)\n",
    "#             gc_val=metrics.gck(uid,training_matrix,poi_cats,predicted_at_k)\n",
    "#             epc_val=metrics.epck(predicted_at_k,actual,uid,training_matrix)\n",
    "            \n",
    "#             mcs[i].append_data([precision_val,rec_val,pr_val,ild_val,gc_val,epc_val])\n",
    "#             print(\"userid →\",uid,end=',')\n",
    "#             mcs[i].print_metrics()\n",
    "\n",
    "#,f\"prec@{N}: {np.mean(precision)}, rec@{N}: {np.mean(recall)}\")\n",
    "#         print(final_scores)\n",
    "#         print(rec_list)\n",
    "#         print(list(reversed(np.sort(final_scores))))\n",
    "#         print(np.array(rec_list)[list(reversed(np.argsort(final_scores)))])\n",
    "#         print()\n",
    "# for i in mcs:\n",
    "#     i.fwrite_metrics()\n",
    "\n",
    "executor = ProcessPoolExecutor()\n",
    "\n",
    "futures =[executor.submit(run_geocat,uid) for uid in all_uids]\n",
    "results = [future.result() for future in futures]\n",
    "\n",
    "result_out = open(\"../data/result/reclist/\"+CITY+\"_geocat_\" + str(K) + \".json\", 'w')\n",
    "for json_string_result in results:\n",
    "    result_out.write(json_string_result)\n",
    "result_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
